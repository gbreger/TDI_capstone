{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "53396a8b",
   "metadata": {},
   "source": [
    "This notebook contains the ML model that predicts log of the sales. It could just as well predict the sales themselves, but given the range of values for sales, it makes more sense to predict the log. An error of \\\\$50,000 on a 1.5 million dollars game would be less substantial than the same error on a \\\\$100,000 game."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "add8b3ee",
   "metadata": {},
   "source": [
    "The notebook assumes that the data set is already cleaned and ready to be used. See the data engineering notebook for the data preparation.\n",
    "\n",
    "There are three kinds of columns in the data set: numerical (e.g. sales), categorical (e.g. platform, genre), and free-form text (e.g. summary). The numerical data does not require any further preparation. The categorical data will be one-hot encoded. Some categorical columns contain singular values and will be transformed using OneHotEncoder. Other categorical columns contain lists that will use DictVectorizer. Note that the majority of the categorical columns contain numerical values, but these simply represent different classes of whatever data the columns hold. The free-form text will be transformed using TF-IDF vectorizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c697d9c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', 50)\n",
    "pd.set_option('display.max_rows', 50)\n",
    "\n",
    "from tdi_capstone_common_functions import *\n",
    "# the two functions imported are: standardize_string and pseudo_list_parser"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "928488c2",
   "metadata": {},
   "source": [
    "The data, loaded into a pandas data frame, has a lot of columns. While the data engineering notebook dropped columns that were not useful for predictions, specifically a lot of meta-data (e.g., the url for the game on IGDB), there are still columns that may be useful, but may as well not be. They were retained up to this point, but are now dropped. They may be used in future versions of the model. Some, however, can and shouled be dropped regardless, such asname, release_year, closest_match, match_score, id, first_release_date, and release_dates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e5680923",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data\n",
    "drop_columns = [\n",
    "    'name',\n",
    "    'release_year',\n",
    "    'closest_match',\n",
    "    'match_score',\n",
    "    'id',\n",
    "    'first_release_date',\n",
    "    'release_dates',\n",
    "    'alternative_names',\n",
    "    'external_games',\n",
    "    'similar_games',\n",
    "    'language_supports',\n",
    "    'status',\n",
    "    'bundles',\n",
    "    'collections',\n",
    "    'parent_game',\n",
    "    'collection'\n",
    "    ]\n",
    "\n",
    "df = (pd.read_csv('data_complete.csv', index_col='index')\n",
    "      .drop(drop_columns, axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f98c323",
   "metadata": {},
   "source": [
    "Since different kinds of columns will be transformed using different transformers, it is easy to create lists of columns according to their kind."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e4edf26f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# columns with numerical data\n",
    "numeric_columns = ['sales_na', 'sales_eu', 'sales_jp', 'sales_other', 'sales_global']\n",
    "\n",
    "# columns with free-form text\n",
    "text_columns = ['summary', 'storyline']\n",
    "\n",
    "# columns that contain lists (imported as strings that look like lists)\n",
    "list_columns = ['age_ratings', 'game_modes', 'genres', 'themes', 'involved_companies', 'keywords',\n",
    "               'multiplayer_modes', 'franchises', 'game_engines', 'player_perspectives', 'game_localizations']\n",
    "\n",
    "# parse the columns that contain pseudo-lists into lists and populate those with a non-list (NaN) with an empty list\n",
    "df[list_columns] = df[list_columns].applymap(lambda x: pseudo_list_parser(x)).applymap(lambda x: x if isinstance(x, list) else [])\n",
    "\n",
    "# since most columns won't use OneHotEncoder, it is easier to exclude columns from df.columns than to explicitly list them out\n",
    "non_ohe_columns = numeric_columns + text_columns + list_columns\n",
    "# creates a list with the columns that do not appear in any of the above lists\n",
    "ohe_columns = [column_name for column_name in df.columns if column_name not in non_ohe_columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7d0746c",
   "metadata": {},
   "source": [
    "## Building the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3ebcc353",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "\n",
    "from sklearn.decomposition import TruncatedSVD # used for dimensionality reduction\n",
    "\n",
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "922aa8d1",
   "metadata": {},
   "source": [
    "As mentioned above, there are three kinds of columns: numerical, categorical, and free-form text. Numerical data does not require any transformation at this point. The categorical columns can be divided into two subtypes, columns with singular values that will be transformed using OneHotEncoder and columns with lists of values that will be transformed with DictVectorizer. Lastly, free-form text will use TfidfVectorizer. Each of these kinds of transformations will be stored as a list of transformers with their relevant columns, so they can all eventually be put together into a single list of transformers passed onto the ColumnTransformer of the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e5eddb7",
   "metadata": {},
   "source": [
    "First to be treated are the OneHotEncoder categorical columns. It is created as a tuple (per usual format of transformers) and then places into a list, so that it can easily be added to the other transformers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3d6dd6a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe_transformers = [('categorical', OneHotEncoder(handle_unknown='ignore'), ohe_columns)]\n",
    "#ohe_transformer = ('categorical', OneHotEncoder(handle_unknown='ignore'), ohe_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0938d0e6",
   "metadata": {},
   "source": [
    "Then the categorical columns with lists of values. Each one of these lists is first encoded as a dictionary (using a custom class) and then vectorized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1374c030",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DictEncoder(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "#         X_trans = pd.DataFrame()\n",
    "        \n",
    "#         for column in X.columns:\n",
    "#             column_trans = [{key: 1 for key in item} for item in X[column]]\n",
    "#             X_trans[column] = column_trans\n",
    "        \n",
    "#         return X_trans\n",
    "        return [{key: 1 for key in row} for row in X] #, name=X.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6651fae8",
   "metadata": {},
   "source": [
    "Because the transformer first needs to encode and then vectorize the list, a pipeline is used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bc1bd779",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_column_vectorizer = Pipeline([\n",
    "    ('dict_encoder', DictEncoder()),\n",
    "    ('dict_vectorizer', DictVectorizer())\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a1d3512",
   "metadata": {},
   "source": [
    "Then a list is created, where every element is the tuple format of a transformer (name, transformer, column(s)) for every column. This way, it is possible to access specific transformers by its name via the named_steps method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a7ae72fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_column_transformers = [(f'list_vect_{column}', list_column_vectorizer, f'{column}') for column in list_columns]\n",
    "#list_column_transformer = ('list_columns', list_column_vectorizer, list_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "672de3d2",
   "metadata": {},
   "source": [
    "Lastly, the free-form text columns are treated, where the strings are first standardized and then vectorized using TF-IDF. Very rare words are excluded, represented by the min_df value. Additionally, a relatively low max_df is set to exclude words that appear in a lot of game descriptions, since we want to use the most impactful words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c02816ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_column_preprocessing(series):\n",
    "    \"\"\"\n",
    "    Standardizes a series containing free-form strings.\n",
    "    \n",
    "    Parameter\n",
    "    ---------\n",
    "    series : pandas.Series()\n",
    "        A series of strings to be standardized, retaining only alphanumeric characters,\n",
    "        changing East Asian characters into Latin ones, and removing symbols and parentheses.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    pandas.Series\n",
    "        A series of standardized strings.\n",
    "    \"\"\"\n",
    "    \n",
    "    return series.map(standardize_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ab35f807",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "\n",
    "STOP_WORDS = STOP_WORDS.difference({'he','his','her','hers'}).union({'ll', 've'})\n",
    "\n",
    "text_column_vectorizer = Pipeline([\n",
    "    ('standardize_text', FunctionTransformer(text_column_preprocessing)),\n",
    "    ('tfidf', TfidfVectorizer(min_df=20, max_df=0.5, stop_words=list(STOP_WORDS)))\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1f75d87",
   "metadata": {},
   "source": [
    "Much like in the case with the list columns, a list of tuples is created, each referring to an individual free-form text column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b77814e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_column_transformers = [(f'text_{column}', text_column_vectorizer, f'{column}') for column in text_columns]\n",
    "#text_column_transformer = ('text_columns', text_column_vectorizer, text_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27d858d8",
   "metadata": {},
   "source": [
    "It is now possible to build the model. All the features will undergo their respective transformations (remember that the numerical columns do not need any at this point)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "de23d512",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ColumnTransformer(\n",
    "    transformers = list_column_transformers + ohe_transformers + text_column_transformers,\n",
    "    remainder='drop')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f45cc60",
   "metadata": {},
   "source": [
    "The model was trained with several regressors alongside appropriate parameter grids. These include LinearRegression, Ridge, RandomForestRegressor, and KNeighborsRegressor. Out of all of them, Ridge seemed to performed the best. In order to streamline building different versions of the model, a function allows for a quick customization of the regressor."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a59134d",
   "metadata": {},
   "source": [
    "Note that the data set ends up having quite a lot of features, particularly due to the free-form text vectorizer. Given the number of observations, this needs to be taken into account. To balance that, some kind of dimensionality reduction can help to improve the model. Post-transformation, the data is stored in a sparse matrix, and since PCA doesn't work with sparse data, we'll use TruncatedSVD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8c3a5486",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_regressor(requested_model='ridge', hyperparameters=None, requested_dr='default', cv=5, n_jobs=2):\n",
    "    \"\"\"\n",
    "    Creates a regressor with grid search cross-validation.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    requested_model : string or sklearn model, default 'ridge'\n",
    "        The name of the model as a string or an instantiated model\n",
    "        object itself. Currently supported models: LinearRegression, Ridge,\n",
    "        RandomForestRegressor, KNeighborsRegressor. Defaults to Ridge\n",
    "        if anything else is given.\n",
    "    hyperparameters : dict, default None\n",
    "        The hyperparameters for grid search cross-validation based on\n",
    "        the regressor. If not passed, defaults to the built-in ones.\n",
    "    requested_dr : string or list, default 'default'\n",
    "        Indicates how dimensionality reduction using TruncatedSVD should\n",
    "        work. Accepted strings are 'default' for the default values based\n",
    "        on the model chosen, 'aggressive' to reduce to hundreds of features,\n",
    "        or 'relaxed' to reduce to tens of features. Alternatively, a list\n",
    "        can be passed with the possible values.\n",
    "    cv : int, default 5\n",
    "        The number of folds in the cross validation.\n",
    "    n_jobs : int, default 2\n",
    "        The number of parallel jobs for the cross validation.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    GridSearchCV object\n",
    "        An object based on the requested model or the default if that\n",
    "        type of regressor is not supported by the function. The parameter\n",
    "        grid is also set for the specified model.\n",
    "    \n",
    "    Notes\n",
    "    -----\n",
    "    The currently supported models are linear regression, ridge, random\n",
    "    forest, and k-nearest neighbors. All but the last one use a relaxed\n",
    "    dimensionality reduction (n_components = [100, 250, 500]) by default,\n",
    "    with k-nearest neighbors using an aggressive one\n",
    "    (n_components = [10, 20, 30]). The built-in default hyperparameters\n",
    "    for each are as follows:\n",
    "        Ridge :\n",
    "            'alpha': [0.1, 1.0, 10.0]\n",
    "        Random Forest :\n",
    "            'n_estimators': [10, 50, 100, 200, 300],\n",
    "            'max_depth': [None, 10, 20, 50],\n",
    "            'min_samples_split': [2, 5, 10],\n",
    "            'min_samples_leaf': [1, 2, 4]\n",
    "        K-Nearest Neighbors :\n",
    "            'n_neighbors': [3, 5, 8, 10, 15]  \n",
    "    \"\"\"\n",
    "\n",
    "    #\n",
    "    if isinstance(requested_model, str):\n",
    "        supported_models = {\n",
    "            'linearregression': LinearRegression(),\n",
    "            'lr': LinearRegression(),\n",
    "            'linear': LinearRegression(),\n",
    "            'ridge': Ridge(),\n",
    "            'randomforestregressor': RandomForestRegressor(),\n",
    "            'randomforest': RandomForestRegressor(),\n",
    "            'kneighborsregressor': KNeighborsRegressor(),\n",
    "            'knn': KNeighborsRegressor()\n",
    "        }\n",
    "        \n",
    "        model = supported_models.get(requested_model.lower(), Ridge())\n",
    "        \n",
    "    # The default values for dimensionality reduction\n",
    "    dr_values = {\n",
    "        'relaxed': [100, 250, 500],\n",
    "        'aggressive': [10, 20, 30] # for, e.g., KNN\n",
    "    }\n",
    "    \n",
    "    # if the function was passed a specific list of dimensionality reduction values, it will use that list\n",
    "    if isinstance(requested_dr, list):\n",
    "        dr = requested_dr\n",
    "    else:\n",
    "        # if a string was passed, it will use one of the two built-in options, either aggressive or relaxed dimensionality\n",
    "        # reduction; or if the string was 'default' or another non-supported string, it will use a default set of values.\n",
    "        # These are based on the model requested, and so a function is used to determine which of the two built-in options\n",
    "        # to use.\n",
    "        def find_default_dr(model_for_dr):\n",
    "            aggressive_dr_models = [KNeighborsRegressor] # list of models which default to aggressive dimensionality reduction\n",
    "            \n",
    "            if model_for_dr in aggressive_dr_models:\n",
    "                return dr_values['aggressive']\n",
    "            \n",
    "            return dr_values['relaxed']\n",
    "        \n",
    "        # find the correct built-in value for dimensionality reduction\n",
    "        dr = dr_values.get(requested_dr, find_default_dr(model))\n",
    "\n",
    "    # Initiliazes the dimensionality reduction object\n",
    "    svd = TruncatedSVD()\n",
    "    \n",
    "    # Initializes the parameter grid with the dimensionality reduction values\n",
    "    param_grid = {'dim_reduction__n_components': dr}\n",
    "    \n",
    "    # If no parameter grid was passed, use the built-in values\n",
    "    if not hyperparameters:\n",
    "        \n",
    "        if isinstance(model, Ridge):\n",
    "            hyperparameters = {\n",
    "                'alpha': [0.1, 1.0, 10.0]\n",
    "            }\n",
    "        elif isinstance(model, RandomForestRegressor):\n",
    "            hyperparameters = {\n",
    "                'n_estimators': [10, 50, 100, 200, 300],\n",
    "                'max_depth': [None, 10, 20, 50],\n",
    "                'min_samples_split': [2, 5, 10],\n",
    "                'min_samples_leaf': [1, 2, 4]\n",
    "            }\n",
    "        elif isinstance(model, KNeighborsRegressor):\n",
    "            hyperparameters = {\n",
    "                'n_neighbors': [3, 5, 8, 10, 15]   \n",
    "            }\n",
    "        else: # default if model does not have hyperparameters, e.g. linear regression\n",
    "            hyperparameters = {}\n",
    "    \n",
    "    # renames the keys so they can be properly accessed\n",
    "    hyperparameters = {f'regressor__{k}' : v for k, v in hyperparameters.items()}\n",
    "        \n",
    "    # Updates the parameter grid (currently only with dimensionality reduction) with the regressor's hyperparameters.\n",
    "    param_grid.update(hyperparameters)\n",
    "        \n",
    "    estimator = Pipeline([\n",
    "        ('dim_reduction', svd),\n",
    "        ('regressor', model)\n",
    "    ])\n",
    "\n",
    "    gs = GridSearchCV(\n",
    "        estimator,\n",
    "        param_grid=param_grid,\n",
    "        cv=cv,\n",
    "        n_jobs=n_jobs\n",
    "    )\n",
    "\n",
    "    return gs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cb2398f",
   "metadata": {},
   "source": [
    "It is then possible to build the model with different kinds of regression algorithms or parameter grids. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef7bbb1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Pipeline([\n",
    "    ('features', features),\n",
    "    ('main_regressor', generate_regressor('ridge'))\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c96b7298",
   "metadata": {},
   "source": [
    "## Training the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65a95e52",
   "metadata": {},
   "source": [
    "As mentioned above, the numerical columns are only the sales, which are also the (basis of the) labels, so these can be dropped from the feature matrix passed onto the model. The labels are going to be the log of the global sales. In the future, it would be possible to have the model predict localized sales (e.g. EU, US, etc)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "343f0c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(numeric_columns, axis=1)\n",
    "y = np.log(df['sales_global'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7742e7b7",
   "metadata": {},
   "source": [
    "The data is then split into a training set and a test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d3481eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a0c0502",
   "metadata": {},
   "source": [
    "The model is then fit with the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c3e3021",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9774e92b",
   "metadata": {},
   "source": [
    "Alternatively, we can train several different models on the same train/test data split and save them as a dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "348ad2be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# algorithms = ['lr', 'ridge', 'knn', 'randomforest']\n",
    "\n",
    "# models = dict()\n",
    "\n",
    "# for algorithm in algorithms:\n",
    "#     model = Pipeline([\n",
    "#         ('features', features),\n",
    "#         ('main_regressor', generate_regressor(algorithm, cv=10, n_jobs=-1))\n",
    "#     ])\n",
    "#     model.fit(X_train, y_train)\n",
    "#     models[algorithm] = model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1d81144",
   "metadata": {},
   "source": [
    "## Saving the trained model\n",
    "The model can then be serialized and saved into a file so it doesn't have to be trained again. A container (list) object is created that will hold the model itself, as well as the train/test split of the data that was used in its training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ca8d1650",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "data_container = [model, X_train, X_test, y_train, y_test]\n",
    "\n",
    "with open('model.pickle', 'wb') as f:\n",
    "    pickle.dump(data_container, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fc3004f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If we trained several models and saved them as a dictionary, we can then save them into different files.\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    with open(f'{model_name}.pickle', 'wb') as f:\n",
    "        data_container = [model, X_train, X_test, y_train, y_test]\n",
    "        pickle.dump(data_container, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dca4b72",
   "metadata": {},
   "source": [
    "If the model has already been pickled, it can be imported."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0d4183dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('model', 'rb') as f:\n",
    "    loaded_container = pickle.load(f)\n",
    "\n",
    "model, X_train, X_test, y_train, y_test = loaded_container"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c9e121b",
   "metadata": {},
   "source": [
    "If multiple models were pickled using the models dictionary, they can all be loaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3641dbcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONTINUE HERE!!!\n",
    "model_container = {'model': model, 'X_train': X_train, 'X_test': X_test, 'y_train': y_train, 'y_test': y_test}\n",
    "\n",
    "algorithms = ['lr', 'ridge', 'knn', 'randomforest']\n",
    "\n",
    "loaded_models = dict()\n",
    "\n",
    "for algorithm in algorithms:\n",
    "    with open(f'{algorithm}.pickle', 'rb') as f:\n",
    "        loaded_container = pickle.load(f)\n",
    "        loaded_models[algorithm]\n",
    "        \n",
    "#     model = Pipeline([\n",
    "#         ('features', features),\n",
    "#         ('main_regressor', generate_regressor(algorithm, cv=10, n_jobs=-1))\n",
    "#     ])\n",
    "#     model.fit(X_train, y_train)\n",
    "#     models[algorithm] = model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e89966d",
   "metadata": {},
   "source": [
    "Predictions can then be made:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92fb98d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aa16f5b",
   "metadata": {},
   "source": [
    "# Assessing and visualizing model performance\n",
    "It's then possible to observe some metrics on the performance of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31367437",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88b13e2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = {'lr': lr_y_pred, 'ridge': ridge_y_pred, 'knn': knn_y_pred}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d348f00c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, y_pred in preds.items():\n",
    "    print(f'For {key}:')\n",
    "    print(f\"Mean absolute error: {metrics.mean_absolute_error(y_test, y_pred)}\")\n",
    "    print(f\"Mean squared error: {metrics.mean_squared_error(y_test, y_pred)}\")\n",
    "    print(f\"R^2: {metrics.r2_score(y_test, y_pred)}\")\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9129eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_pred = pipe.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "666ff214",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(f\"Mean absolute error: {metrics.mean_absolute_error(y_test, y_pred)}\")\n",
    "# print(f\"Mean squared error: {metrics.mean_squared_error(y_test, y_pred)}\")\n",
    "# print(f\"R^2: {metrics.r2_score(y_test, y_pred)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77b83903",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pipe.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6124d3c3",
   "metadata": {},
   "source": [
    "## Data visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50820251",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import pickle\n",
    "from ipywidgets import widgets\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# df_housing = pd.read_csv('small_data/Housing_Train.csv')\n",
    "# with open('small_data/Housing_Train_dict.pkl', \"rb\") as f:\n",
    "#     features_dict = pickle.load(f)\n",
    "\n",
    "# X = df_housing.drop('SalePrice', axis=1)\n",
    "# y = df_housing['SalePrice']\n",
    "\n",
    "def housing_plot(X, y):\n",
    "    def plotter(column):\n",
    "        valid_rows = X[column].notna()\n",
    "        plt.plot(X.loc[valid_rows, column], y[valid_rows], '.', color='k')\n",
    "#         plt.xlabel(features_dict[column])\n",
    "        plt.ylabel('Global sales (mil $)')\n",
    "    \n",
    "    return plotter\n",
    "\n",
    "# dropdown_values = {f\"{k}: {features_dict[k]}\": k for k in sorted(X.columns)}\n",
    "# widgets.interact(housing_plot(X, y), column=dropdown_values);\n",
    "widgets.interact(housing_plot(X_train, y_train), column=X_train.columns);\n",
    "\n",
    "# dropdown_values = {f\"{k}: {features_dict[k]}\": k for k in sorted(X.columns)}\n",
    "# widgets.interact(housing_plot(X, y), column=dropdown_values);\n",
    "\n",
    "# NOTE: This doesn't currently work with the columns that have lists as values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd894c3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scatter plot of actual versus predicted values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c663c91b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def plot_predicted_vs_actual(actual_values, predicted_values):\n",
    "#     plt.figure(figsize=(10, 6))\n",
    "#     plt.scatter(actual_values, predicted_values, alpha=0.5, label='Predicted vs Actual')\n",
    "#     plt.plot([min(actual_values), max(actual_values)], [min(actual_values), max(actual_values)], color='red', linestyle='--', label='Perfect Prediction')\n",
    "#     plt.xlabel('Actual Log Sales')\n",
    "#     plt.ylabel('Predicted Log Sales')\n",
    "#     plt.title('Actual vs Predicted Log Sales')\n",
    "#     plt.legend()\n",
    "#     plt.show()\n",
    "\n",
    "# plot_predicted_vs_actual(y_test, y_pred)\n",
    "# plot_predicted_vs_actual(np.exp(y_test), np.exp(y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "98d688d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_predicted_vs_actual_enhanced(actual_values, predicted_values, extras='log of sales'):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.scatterplot(x=actual_values, y=predicted_values, alpha=0.5)\n",
    "    sns.lineplot(x=[min(actual_values), max(actual_values)], y=[min(actual_values), max(actual_values)], color='red', linestyle='--')\n",
    "    plt.xlabel(f'Actual values ({extras})')\n",
    "    plt.ylabel(f'Predicted values ({extras})')\n",
    "    plt.title(f'Actual vs predicted values ({extras})')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eed0c476",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_predicted_vs_actual_enhanced(y_test, lr_y_pred)\n",
    "# plot_predicted_vs_actual_enhanced(np.exp(y_test), np.exp(lr_y_pred), 'mil $')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f2dcbe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_predicted_vs_actual_enhanced(y_test, ridge_y_pred)\n",
    "# plot_predicted_vs_actual_enhanced(np.exp(y_test), np.exp(ridge_y_pred), 'mil $')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c96a482c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_predicted_vs_actual_enhanced(y_test, knn_y_pred)\n",
    "# plot_predicted_vs_actual_enhanced(np.exp(y_test), np.exp(knn_y_pred), 'mil $')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49be322c",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "actual_values = np.random.normal(loc=10, scale=2, size=100)\n",
    "predicted_values = actual_values + np.random.normal(loc=0, scale=1, size=100)\n",
    "\n",
    "# plot_predicted_vs_actual(actual_values, predicted_values)\n",
    "plot_predicted_vs_actual_enhanced(actual_values, predicted_values, 'mil $')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "02a1cf87",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'lr_y_pred' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[54], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mseaborn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msns\u001b[39;00m\n\u001b[0;32m      3\u001b[0m actual_values \u001b[38;5;241m=\u001b[39m y_test\n\u001b[1;32m----> 4\u001b[0m predicted_values \u001b[38;5;241m=\u001b[39m \u001b[43mlr_y_pred\u001b[49m\n\u001b[0;32m      6\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m6\u001b[39m))\n\u001b[0;32m      7\u001b[0m sns\u001b[38;5;241m.\u001b[39mhistplot(actual_values, color\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mblue\u001b[39m\u001b[38;5;124m'\u001b[39m, label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mActual\u001b[39m\u001b[38;5;124m'\u001b[39m, kde\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'lr_y_pred' is not defined"
     ]
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "actual_values = y_test\n",
    "predicted_values = lr_y_pred\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(actual_values, color='blue', label='Actual', kde=True)\n",
    "sns.histplot(predicted_values, color='orange', label='Predicted', kde=True)\n",
    "plt.xlabel('Log Sales')\n",
    "plt.title('Distribution of Actual and Predicted Log Sales')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "8239eda1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Model      RMSE        R\n",
      "0            lr  1.072045  0.519700\n",
      "1         ridge  1.082502  0.510285\n",
      "2           knn  1.147199  0.449998\n",
      "3  randomforest  1.137848  0.458928\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "metrics = []\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    y_pred = model.predict(X_test)\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    metrics.append({'Model': model_name, 'RMSE': rmse, 'R': r2})\n",
    "\n",
    "metrics_df = pd.DataFrame(metrics)\n",
    "\n",
    "# Bar plot\n",
    "metrics_df.set_index('Model')[['RMSE', 'R']].plot(kind='bar', figsize=(10, 6))\n",
    "plt.title('Model Performance Comparison')\n",
    "plt.ylabel('Score')\n",
    "plt.show()\n",
    "\n",
    "# Alternatively, print the table\n",
    "print(metrics_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d359dcf6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0e98cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# svd = TruncatedSVD()\n",
    "\n",
    "# regressor = Ridge()\n",
    "# #regressor = RandomForestRegressor()\n",
    "# # regressor = KNeighborsRegressor()\n",
    "\n",
    "# param_grid = {\n",
    "# # relaxed dimensionality reduction:\n",
    "#     'dim_reduction__n_components': [100, 250, 500],\n",
    "# # aggresive dimensionality reduction (for, e.g., KNN):\n",
    "# #     'dim_reduction__n_components': [10, 20, 30],\n",
    "\n",
    "# # Ridge hyperparameters\n",
    "#    'regressor__alpha': [0.1, 1.0, 10.0]\n",
    "# # KNN hyperparameters\n",
    "# #     'regressor__n_neighbors': [3, 5, 8, 10, 15]\n",
    "# # RandomForest hyperparameters:\n",
    "# #     'regressor__n_estimators': [10, 50, 100],#, 200, 300],\n",
    "# #     'regressor__max_depth': [None, 10, 30], # 20, 50],\n",
    "# #     'regressor__min_samples_split': [2, 5, 10],\n",
    "# #     'regressor__min_samples_leaf': [1, 2, 4]\n",
    "# }\n",
    "\n",
    "# estimator = Pipeline([\n",
    "#     ('dim_reduction', svd),\n",
    "#     ('regressor', regressor)\n",
    "# ])\n",
    "\n",
    "# gs = GridSearchCV(\n",
    "#     estimator,\n",
    "#     param_grid=param_grid,\n",
    "#     cv=5,\n",
    "#     n_jobs=2\n",
    "# )\n",
    "\n",
    "# pipe = Pipeline([\n",
    "#     ('features', features),\n",
    "#     ('main_regressor', gs)\n",
    "# ])\n",
    "\n",
    "# pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f33c0535",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # exploration of accessing feature importance for difference models\n",
    "\n",
    "# # for ridge\n",
    "# models['ridge'].named_steps.main_regressor.best_estimator_.named_steps.regressor.coef_\n",
    "# models['ridge'].named_steps.features.named_transformers_.categorical.get_feature_names_out(ohe_columns)\n",
    "\n",
    "# # for random forest\n",
    "# comp = models['randomforest'].named_steps.main_regressor.best_estimator_.named_steps.dim_reduction.components_\n",
    "# feat = models['randomforest'].named_steps.main_regressor.best_estimator_.named_steps.regressor.feature_importances_\n",
    "\n",
    "# # \n",
    "# original_import = np.dot(feat, np.abs(comp))\n",
    "# original_import.shape # this will give the total number of original features\n",
    "# models['randomforest'].named_steps.features.output_indices_ # will lay out the ranges for each feature, e.g., genre takes up\n",
    "# # features 1598-1642 in the post-transformation feature matrix\n",
    "\n",
    "# # models['randomforest'].named_steps.features.get_feature_names_out()\n",
    "# # This gives an attribute error for dict_encoder, most likely because it's a custom class that does not have that method"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
