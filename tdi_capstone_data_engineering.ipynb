{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0ccb9fd7",
   "metadata": {},
   "source": [
    "## games info data base columns:\n",
    "\n",
    "### features to keep:\n",
    "* first_release_date = first date game was released\n",
    "* game mode = e.g. single player, multiplayer, etc\n",
    "* genres\n",
    "* name\n",
    "* platforms\n",
    "* summary = text description of game, to be captured using nlp\n",
    "* themes\n",
    "* involved_companies = in development\n",
    "* keywords = e.g., 'world war 2', 'steampunk'; may be sparse, so unclear if useable\n",
    "* multiplayer_modes\n",
    "* franchise (see also franchises)\n",
    "* game_engines - need to dig further, but likely things like, unity, unreal, etc\n",
    "* player_perspectives\n",
    "* storyline\n",
    "\n",
    "### features to consider:\n",
    "* age_rating = a code referring to one of the age rating associations, e.g., pegi, esrb\n",
    "* category = majority over 226k entries have category 0, remained 38k+ has other values; 0 = main_game, 1 = dlc, 2 = expansion...\n",
    "* external_games = external platforms game is available on, e.g. steam, gog, twitch, epic\n",
    "* release_dates = provided in-depth information on release dates per region/platform/etc\n",
    "* language_supports\n",
    "* status = 0 = released, 2 = alpha, 3 = beta, 4 = early access, etc\n",
    "* alternative names = might be useful to find near matches\n",
    "* bundles = which bundles contain this game\n",
    "* game_localization = might be significant\n",
    "* collections = the collections this game belongs to (worth exploring)\n",
    "* collection = the series the game belongs to (worth exploring)\n",
    "* ports = of the game (worth exploring)\n",
    "* franchises = other franchises this belongs to (see also franchise)\n",
    "* forks = IDs of forks of this game (no idea what that means)\n",
    "\n",
    "### features to drop:\n",
    "* artworks = can't find it, but has api, so likely can access via api\n",
    "* cover = cover art\n",
    "* created_at = when added to igdb\n",
    "* screenshots = for future development on capturing art style\n",
    "* slug = unique url-name-string\n",
    "* tags = auto-generated numbers that allow complex filtering on the igdb api (DROP!)\n",
    "* updated_at = last time game entry was updated\n",
    "* url = link to game website\n",
    "* version_parent = if entry is a version of game, this column has the original parent game id(?)\n",
    "* version_title = title of this version, e.g., Gold edition\n",
    "* checksum = hash of the game(?!)\n",
    "* websites = websites associated with game (url = igdb; websites = developer/publisher)\n",
    "* follows = no. people following game, depricated\n",
    "* videos = of gameplay\n",
    "* hypes = no. people following before release\n",
    "* dlcs = of the game, their IDs\n",
    "* expansions\n",
    "* remakes = IDs of remakes of this game\n",
    "* expanded_games = of this game, game IDs\n",
    "* remasters = ID of games that are remasters of this ID\n",
    "* standalone_expansions = IDs of exactly what it says\n",
    "* aggregated_rating = based on external critic scores\n",
    "* aggregated_rating_count = how many external scores\n",
    "* rating = average rating on igdb\n",
    "* rating_count = how many ratings on igdb\n",
    "* total_rating = average rating based on external and igdb rating\n",
    "* total_rating_count = how many ratings in all (external and igdb)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94ba1173",
   "metadata": {},
   "source": [
    "## Library imports, settings, and global function definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c52ede48",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', 50)\n",
    "pd.set_option('display.max_rows', 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2def6456",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A unique game entry is defined by the unique combination of the following parameters\n",
    "\n",
    "unique_game = ['name', 'platform', 'release_year']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f0f345f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# confine the data set to certain years, here 2010-2020 (inclusive)\n",
    "\n",
    "time_boundaries = {'start': 2010, 'end': 2020}\n",
    "\n",
    "# Function that filters the dataframe for a specified range of years.\n",
    "# Returns the filtered dataframe.\n",
    "# Parameters:\n",
    "# - df = DataFrame, the dataframe to be filtered\n",
    "# - column = str, name of the column containing the filtered parameter, in this case years\n",
    "# - time_limits = dict (default = time_boundaries), dict containing the start and end of the range of years to serve as filter\n",
    "# - include_start = bool (default = True), whether to include the start of the range in the accept range of years\n",
    "# - include_end = bool (default = False), whether to include the end of the range in the accepted range of years\n",
    "# - flag = bool (default = False), whether to include rows that have been flagged for missing values\n",
    "\n",
    "def filter_by_time_boundaries(df, column, time_limits=time_boundaries, include_start=True, include_end=True, flag=False):\n",
    "\n",
    "    # sets up the filter based on the start of the range\n",
    "    if include_start:\n",
    "        start_filter = (df[column] >= time_limits['start'])\n",
    "    else:\n",
    "        start_filter = (df[column] > time_limits['start'])\n",
    "    \n",
    "    # sets up the filter based on the end of the range\n",
    "    if include_end:\n",
    "        end_filter = (df[column] <= time_limits['end'])\n",
    "    else:\n",
    "        end_filter = (df[column] < time_limits['end'])\n",
    "    \n",
    "    # sets up the filter based on whether to include rows flagge for missing values\n",
    "    if flag:\n",
    "        flagged_filter = (df[column] == flag)\n",
    "        \n",
    "        # return rows if they fall between start and end (inclusive or exclusive) or if rows were flagged for missing values\n",
    "        return df[(start_filter & end_filter) | flagged_filter]\n",
    "    \n",
    "    # return only rows that fall between start and end (inclusive or exclusive), excluding flagged rows\n",
    "    return df[start_filter & end_filter]\n",
    "\n",
    "# Note: currently the project filters out games who did not have a release year (marked with a flag of -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d3cf70dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function converts a variable from one data type to another if possible.\n",
    "# Returns a value converted into a new datatype, or a flag value (default = -1) if unsuccessful due to ValueError.\n",
    "# Parameters:\n",
    "# - value = the value to be cast\n",
    "# - new_type = the data type of value\n",
    "# - flag = (default = -1) the value to be returned in case conversion was unsuccessful due to ValueError, e.g. casting np.nan\n",
    "# as an int\n",
    "\n",
    "def convert_types(value, new_type, flag=-1):\n",
    "    try:\n",
    "        return new_type(value)\n",
    "    except ValueError:\n",
    "        return flag\n",
    "\n",
    "# This function require a lambda function to be passed to the map method, instead of directly mapping this function, i.e.:\n",
    "# .map(lambda x: convert_types(x, <dtype>, <flag>)) instead of, e.g., .map(convert_types)\n",
    "    \n",
    "# Cases this function solves:\n",
    "# 'user_score' (originally string) had 'tbd' \n",
    "# 'release_year' (originally float) had NaN\n",
    "\n",
    "# NOTE: .astype(dtype, errors='ignore') does almost the same, e.g.:\n",
    "# sales_df[sales_df['user_score'] == 'tbd']['user_score'].astype(float, errors='ignore')\n",
    "# In this case, a conversion would take place except where an error occurs, in which case, the original value would be\n",
    "# returned."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcb7d762",
   "metadata": {},
   "source": [
    "Some of columns of the IGDB data set contain lists of values. These, however, are imported as strings, e.g. '[12623, 6231, 96023]'. Therefore, these strings need to be parsed into proper lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "df25cf09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function parses a string into a list of elements of a specified data type, assuming elements are separated by a comma.\n",
    "# Returns a list of elements based on the parsed string or the original item to be parsed, if that item is not a string\n",
    "# (e.g., NaN).\n",
    "# Parameters:\n",
    "# - item = str, the string to be parsed\n",
    "# - dtype = data type (default = int), the data type for each element of the list to be returned\n",
    "# - ignore_space = bool (default = True), whether to remove spaces from the variable item before parsing it\n",
    "\n",
    "def pseudo_list_parser(item, dtype=int, ignore_space=True):\n",
    "\n",
    "    if isinstance(item, str):\n",
    "        if ignore_space:\n",
    "            item = item.replace(' ', '')\n",
    "        return [dtype(x) for x in item.replace('[','').replace(']', '').split(',')]\n",
    "    \n",
    "    return item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cca9c99b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that maps the pseudo_list_parser function onto a series, thereby parsing each value in the series to a list\n",
    "# Returns the mapped, parsed column.\n",
    "# Parameters:\n",
    "# - column = Series, the column containing the values to be parsed\n",
    "# - dtype = data type (default = int), the data type for each element of the list to be returned\n",
    "# - ignore_space = bool (default = True), whether to remove spaces from the variable item before parsing it\n",
    "\n",
    "def column_parser(column, dtype=int, ignore_space=True):\n",
    "    \n",
    "    return column.map(lambda x: pseudo_list_parser(x, dtype, ignore_space))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8c5202f",
   "metadata": {},
   "source": [
    "For the purpose of this project, games are defined as unique based on their name, release year, and platform. Thus, games that share a name but have different release years and/or platforms are considered different games since they can perform differently in terms of sales.\n",
    "\n",
    "In order to merge the two data sets (one containing the sales data and the other containing the game data), it is necessary to standardize and match the values in platforms between the two data sets. That is also true for the two other values that constitute a unique game, namely, game name and release year. Matching names is done further down this notebook and release years are simply integers and do not require any special treatment.\n",
    "\n",
    "The following function maps values of a given feature based on one data set onto the values of the same feature in the other data set. It is used to correlate platform values between the two data sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "19336525",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function maps one set of values to another.\n",
    "# Returns remapped values. This could be a list of values (if a list was passed to the function) or a single value. If there\n",
    "# is no corresponding value to use to map, will return NaN.\n",
    "# Parameters:\n",
    "# - search_key = the value or list of values to be remapped\n",
    "# - value_mapping = dict, in which the dict keys are the values passed as search_key and the corresponding dict values\n",
    "# are the new values.\n",
    "\n",
    "def map_values(search_key, value_mapping):\n",
    "    \n",
    "    # Handling the case in which search_key is a list\n",
    "    if isinstance(search_key, list):\n",
    "        \n",
    "        # initializes the return value as an empty list\n",
    "        remapped_values = []\n",
    "        \n",
    "        # For every item in the search_key list, the loop attempts to find it as a key in the value_mapping dict.\n",
    "        # If it cannot, it continues to the next iteration (due to the if statement).\n",
    "        # If it does, it appends the non-None value to remapped_values, which is the return value of the function\n",
    "        for item in search_key:\n",
    "            \n",
    "            # retrieving the new, remapped value or None if it was not found \n",
    "            value = value_mapping.get(item, None)\n",
    "            \n",
    "            # corresponding values are appended to the return value of the function\n",
    "            if value:\n",
    "                remapped_values.append(value)\n",
    "\n",
    "# FUTURE DEV: switch to the following:\n",
    "#         for item in search_key:\n",
    "#             value = value_mapping.get(item, item)\n",
    "#         remapped_values.append(value)\n",
    "#         remapped_values = list(set(remapped_values))\n",
    "#         this would look in value_mapping to see if it finds a match. If it doesn't, it'll \"keep\" the value as is,\n",
    "#         and when a merge takes place, rows with these values will be dropped, since there will be no match\n",
    "\n",
    "        # If no element in the list search_key appears in value_mapping, set the return value to np.nan.\n",
    "        # If there are elements, make sure to remove any duplicated values.\n",
    "        # Removing this will make the function return an empty list instead of a NaN, as well as duplicated values otherwise.\n",
    "#         if not remapped_values:\n",
    "#             remapped_values = np.nan\n",
    "#         else:\n",
    "#             remapped_values = list(set(remapped_values))\n",
    "    \n",
    "    # Handling the case in which search_key was not a list (function assumes this means it is a single value)\n",
    "    else:\n",
    "        \n",
    "        # retrieves the new, remapped value or NaN if it was not found\n",
    "        remapped_values = value_mapping.get(search_key, np.nan)\n",
    "    \n",
    "    return remapped_values\n",
    "\n",
    "# The following code accomplishes this in a similar way but provides less control of how the function behaves.\n",
    "#     for item in set(l).intersection(value_mapping):\n",
    "#         remapped_values.append(value_mapping[item])\n",
    "# Or:\n",
    "#     remapped_values = [item for item in set(l).intersection(value_mapping)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "677ff7c4",
   "metadata": {},
   "source": [
    "Since names are one of the key features that mark a unique game (the others being release year and platform), it is important to standardize the strings that make up the names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a45d34e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that standardizes strings. It keeps converts diacritics and chinese characters, removes parenthesis, and only\n",
    "# keeps alphanumeric characters.\n",
    "# Returns a lowercase, stripped string of alphanumeric characters.\n",
    "# Parameters:\n",
    "# - string = str, the string to be standardized\n",
    "\n",
    "import re\n",
    "from unidecode import unidecode\n",
    "\n",
    "def standardize_string(string):\n",
    "\n",
    "    # if string is not a str, return an empty string\n",
    "    if not isinstance(string, str):\n",
    "        return ''\n",
    "   \n",
    "    # convert everything to unicode, addressing diacritics as well as chinese characters\n",
    "    string = unidecode(string)\n",
    "    \n",
    "    # remove any non-alphanumeric character or non-space as well as parenthesis (and their enclosed content)\n",
    "    regex = r'\\([^)]*\\)|[^a-zA-Z0-9\\s]'\n",
    "    string = re.sub(regex, '', string)\n",
    "    \n",
    "    # standardize spacing to retain a single space between words\n",
    "    string = re.sub(r'\\s+', ' ', string)\n",
    "    \n",
    "    # change to lowercase and strips whitespaces\n",
    "    return string.lower().strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7afa630",
   "metadata": {},
   "source": [
    "## Sales data import and preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "24a1ffd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the sales data csv into a pandas dataframe\n",
    "\n",
    "# names of the dataframe columns\n",
    "sales_columns = ['index', 'name', 'platform', 'release_year', 'genre', 'publisher',\n",
    "                 'sales_na', 'sales_eu', 'sales_jp', 'sales_other', 'sales_global',\n",
    "                 'critic_score', 'critic_count', 'user_score', 'user_count', 'developer', 'rating']\n",
    "\n",
    "# names of the columns to drop\n",
    "sales_drop_columns = ['critic_score', 'critic_count', 'user_score', 'user_count']\n",
    "\n",
    "# reading csv into dataframe\n",
    "df_sales = (pd.read_csv('sales_data.csv', skiprows=1, names=sales_columns, index_col='index')\n",
    "            .drop(sales_drop_columns, axis=1)\n",
    "            .drop_duplicates() # There are 209 duplicated rows, which are removed here\n",
    "            .dropna(subset=['name'])) # There are 2 rows that have NaN as 'name', which makes them useless"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "df3e8aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transforming the release year column into an int value\n",
    "df_sales['release_year'] = df_sales['release_year'].map(lambda x: convert_types(x, int))\n",
    "\n",
    "# filtering the data by years\n",
    "df_sales = filter_by_time_boundaries(df_sales, 'release_year')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "59a08380",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remember to comment out the time boundaries filter so I find the -1 year games"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3f1329d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_sales[df_sales['release_year'] == -1]['platform'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "512375c9",
   "metadata": {},
   "source": [
    "## Section dealing with rows flagged with missing years\n",
    "\n",
    "Platforms left to do: PS2, Wii, X360, DS, PS3, XB, 2600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "77ba74ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_sales[(df_sales['release_year'] == -1) & (df_sales['platform'] == '2600')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "76e367b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_sales[df_sales['name'].str.contains('Super Robot Wars OG Saga: Masou Kishin II')]['name'][9739]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b8e7f8e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# platform = PC\n",
    "\n",
    "# inversion, 2012\n",
    "# Homeworld Remastered Collection, 2015\n",
    "# WRC: FIA World Rally Championship, 2010\n",
    "# GRID, 2019\n",
    "# Clockwork Empires, 2016\n",
    "# Dead Island: Riptide, 2013\n",
    "# Rocksmith, 2011\n",
    "# Test Drive Unlimited 2, 2011\n",
    "# Dead Space 3, 2013\n",
    "# LEGO Harry Potter: Years 5-7, 2011 | PC, 3DS, PSP\n",
    "# BioShock 2, 2010\n",
    "# Tomb Raider, 2013 \n",
    "# TERA, 2011\n",
    "# Call of Duty: Black Ops, 2010\n",
    "    \n",
    "# Disgaea 3: Absence of Detention, 2011 | PSV\n",
    "    \n",
    "# 3DS\n",
    "# Harvest Moon: The Tale of Two Towns, 2010\n",
    "# Pet Zombies, 2011\n",
    "# Face Racers: Photo Finish, 2011\n",
    "# The Hidden, 2011\n",
    "# Dream Trigger 3D, 2011\n",
    "# Beyond the Labyrinth, 2012\n",
    "\n",
    "# PSP\n",
    "# Danganronpa: Trigger Happy Havoc, 2010\n",
    "# Valkyria Chronicles III: Unrecorded Chronicles, 2011\n",
    "# Super Robot Wars OG Saga: Masou Kishin II - Revelation of Evil God, 2012\n",
    "# Fullmetal Alchemist: Brotherhood, 2010"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a45d610",
   "metadata": {},
   "source": [
    "## End of section for flagged rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ff2029d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# string columns to lowercase\n",
    "regular_string_columns = ['platform', 'genre', 'publisher', 'developer', 'rating']\n",
    "\n",
    "# standardizes string columns with lowercase\n",
    "df_sales[regular_string_columns] = df_sales[regular_string_columns].applymap(lambda x: x.lower() if isinstance(x, str) else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "269b66bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# standardizes strings in the name column, handling non-alphanumeric characters as well as removing parentheses\n",
    "df_sales['name'] = df_sales['name'].map(lambda x: standardize_string(x) if isinstance(x, str) else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c375dc1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# by grouping rows according to unique_game, I eliminate duplicates while saving the max value for other columns, which can be\n",
    "# assumed to be more up-to-date (since sales can only increase, not decrease)\n",
    "\n",
    "df_sales = df_sales.groupby(unique_game).agg('max').reset_index()\n",
    "# Note that for this dataset, this only affects a single game (name = madden nfl 13, platform = ps3, release_year = 2012),\n",
    "# whose sales features are not duplicated and therefore not removed above when duplicated rows are removed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93553039",
   "metadata": {},
   "source": [
    "## Mapping genres between games data and sales data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "52b5b1ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# key = name from df_platforms['id']; value = df_sales['platform']\n",
    "games_to_sales_platform_dict = {\n",
    "    'atari 2600': '2600',\n",
    "    '37': '3ds',\n",
    "    '137': '3ds', # new 3ds\n",
    "    '20': 'ds', # nintendo ds\n",
    "    '159': 'ds', # nintendo dsi\n",
    "    '9': 'ps3',\n",
    "    '7': 'ps2',\n",
    "    '38': 'psp',\n",
    "    '6': 'pc', # windows\n",
    "    '13': 'pc', # DOS\n",
    "    '5': 'wii',\n",
    "    '12': 'x360',\n",
    "    '4': 'n64', # nintendo 64\n",
    "    '21': 'gc', # game cube\n",
    "    '11': 'xb', # xbox\n",
    "    '18': 'nes',\n",
    "    '24': 'gba', # game boy advance\n",
    "    '46': 'psv', # ps vita ; note also '165' = playstation vr, and '390' = playstation vr2 (both not included in this dict)\n",
    "    '48': 'ps4',\n",
    "    '49': 'xone', # xbox one\n",
    "    '19': 'snes', # super NES\n",
    "    '59': '2600', # atari 2600\n",
    "    '41': 'wiiu',\n",
    "    '32': 'sat', # sega saturn\n",
    "    '33': 'gb', # game boy\n",
    "    '22': 'gb', # game boy color\n",
    "    '136': 'ng', # neo geo ; there are other neo geo variations in df_platforms, but there is no relevant game between 2010-2020    \n",
    "    '29': 'gen', # sega genesis\n",
    "    '274': 'pcfx',\n",
    "    '23': 'dc', # dream cast\n",
    "    '50': '3do', # 3do interactive multiplayer\n",
    "    '57': 'ws', # wonderswan\n",
    "    '86': 'tg16', # turbografx-16/pc engine cd\n",
    "    '150': 'tg16', # turbografx-16/pc engine\n",
    "    '78': 'scd', # sega cd\n",
    "    '35': 'gg' # game gear\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55035b37",
   "metadata": {},
   "source": [
    "### Exploration of data\n",
    "\n",
    "I used to following code to determine the correlations of the platforms between df_games and df_sales.\n",
    "I do not need to run any of this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e2d67e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_platforms = pd.read_csv('platforms.csv', index_col='Unnamed: 0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a0f7cc96",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_platforms['name'] = df_platforms['name'].str.lower()\n",
    "#df_platforms['alternative_name'] = df_platforms['alternative_name'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8d623272",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def filter_by_name(df, name):\n",
    "#     filt_alt_name = df['alternative_name'].str.contains(name)\n",
    "#     filt_name = df['name'].str.contains(name)\n",
    "#     filt_slug = df['slug'].str.contains(name)\n",
    "    \n",
    "#     filtered_df = df[filt_alt_name | filt_name | filt_slug]\n",
    "    \n",
    "#     return filtered_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1c167085",
   "metadata": {},
   "outputs": [],
   "source": [
    "#filter_by_name(df_platforms,'gb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1a3fc66b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_sales['platform'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "55e54ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_sales[df_sales['platform'] == 'scd']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee279c5c",
   "metadata": {},
   "source": [
    "## games data import and preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "db5179d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# columns to drop in the games data set\n",
    "\n",
    "games_drop_columns = ['artworks',\n",
    "                      'cover',\n",
    "                      'created_at',\n",
    "                      'screenshots',\n",
    "                      'slug',\n",
    "                      'tags',\n",
    "                      'updated_at',\n",
    "                      'url',\n",
    "                      'version_parent',\n",
    "                      'version_title',\n",
    "                      'checksum',\n",
    "                      'websites',\n",
    "                      'follows',\n",
    "                      'videos',\n",
    "                      'hypes',\n",
    "                      'dlcs',\n",
    "                      'expansions',\n",
    "                      'remakes',\n",
    "                      'expanded_games',\n",
    "                      'remasters',\n",
    "                      'standalone_expansions',\n",
    "                      'aggregated_rating',\n",
    "                      'aggregated_rating_count',\n",
    "                      'rating',\n",
    "                      'rating_count',\n",
    "                      'total_rating',\n",
    "                      'total_rating_count',\n",
    "                      'forks',\n",
    "                      'ports']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4269d6e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# games data set has been split into 10 files due to size, and the following loads all of these ten files as a single dataframe\n",
    "\n",
    "df_games = pd.DataFrame()\n",
    "\n",
    "for i in range(0, 10):\n",
    "    df_partial = pd.read_csv(f'games_data_{i}.csv', low_memory=False, index_col='Unnamed: 0')\n",
    "    df_games = pd.concat([df_games, df_partial], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "de4d3fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping columns that I am not using, renaming platforms to platform (for standardizing purposes), and dropping duplicates\n",
    "\n",
    "df_games = df_games.drop(games_drop_columns, axis=1).rename(columns={'platforms': 'platform'}).drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "582133b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if the games dataset was stored as one file, this command would have done all of the above\n",
    "# df_games = (pd.read_csv('igdb_raw.csv', low_memory=False, index_col='Unnamed: 0')\n",
    "#             .drop(games_drop_columns, axis=1)\n",
    "#             .rename(columns={'platforms': 'platform'})\n",
    "#             .drop_duplicates())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "35a87576",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert first_release_date to a datetime data type\n",
    "df_games['first_release_date'] = pd.to_datetime(df_games['first_release_date'], unit='s')\n",
    "\n",
    "# creates a new column ('release_year') that contains only the year of release\n",
    "df_games['release_year'] = df_games['first_release_date'].dt.year.map(lambda x: convert_types(x, int))\n",
    "\n",
    "# filters data by set time boundaries\n",
    "df_games = filter_by_time_boundaries(df_games, 'release_year')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "eef3f980",
   "metadata": {},
   "outputs": [],
   "source": [
    "# removes all rows that have missing values in any of the fields that define a unique game (name, platform, year)\n",
    "# this can be done with the unique_game variable only after the creation of the 'release_year' column in the cell above\n",
    "\n",
    "df_games = df_games.dropna(how='any', subset=unique_game)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7d2d2df8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# standardizes the name column and drops any row that returned an empty string (i.e. names with only special characters)\n",
    "\n",
    "df_games['name'] = df_games['name'].map(lambda x: standardize_string(x))\n",
    "df_games = df_games[df_games['name'] != '']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "32a100f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converts the platform column from a single string that looks like a list to an actual list of values.\n",
    "# Each element of the list are strings themselves, since the dictionary that maps these values has strings as keys\n",
    "\n",
    "df_games['platform'] = column_parser(df_games['platform'], str)\n",
    "\n",
    "# changes the values in the platforms column to the values used for platform in the df_sales\n",
    "df_games['platform'] = df_games['platform'].map(lambda x: map_values(x, games_to_sales_platform_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "61dcf9a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform rows that have multiple platforms listed into separate rows for each platform, copying all other information\n",
    "\n",
    "df_games = df_games.explode('platform')\n",
    "\n",
    "# Any row that has NaN in the platform field is dropped and any row that has empty strings or lists for any of the\n",
    "# unique_game columns\n",
    "\n",
    "df_games = df_games.dropna(subset=['platform'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2a2487a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# converts all columns except for specific ones\n",
    "\n",
    "columns_not_to_parse = ['id', 'name', 'summary', 'storyline', 'platform', 'release_year']\n",
    "\n",
    "columns_to_parse = list(df_games.columns)\n",
    "\n",
    "# removes columns_not_to_parse from columns_to_parse\n",
    "for column in columns_not_to_parse:\n",
    "    columns_to_parse.remove(column)\n",
    "\n",
    "# parse all relevant columns\n",
    "for column in columns_to_parse:\n",
    "    df_games[column] = column_parser(df_games[column])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "16bb3349",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multiple Values Aggregator\n",
    "# An aggregation function for a dataframe groupby method, aggregating by transforming multiple values into a single\n",
    "# flattened list if possible.\n",
    "# Return value depends on group argument:\n",
    "# - if group is empty, returns NaN\n",
    "# - if group is of length 1, returns the group as is\n",
    "# - otherwise, returns a flattened list containing all elements in group\n",
    "# Parameters:\n",
    "# - group = pandas Series, each column of each group of a groupby operation will be passed to this function as a pandas Series.\n",
    "\n",
    "def mva(group):\n",
    "    \n",
    "    # removes all NaN values\n",
    "    group = group.dropna()\n",
    "    \n",
    "    # if the group is empty, then it means that there were only NaN values in it\n",
    "    if len(group) == 0:\n",
    "        return np.nan\n",
    "    \n",
    "    # if the group has one element, it is the only one that needs to be returned\n",
    "    if len(group) == 1:\n",
    "        return group\n",
    "    \n",
    "    # otherwise, there are multiple elements that need to be combined into a list\n",
    "    aggregated_value = []\n",
    "    \n",
    "    for value in group:\n",
    "        if isinstance(value, list):\n",
    "            aggregated_value.extend(value)\n",
    "        else:\n",
    "            aggregated_value.append(value)\n",
    "        \n",
    "    return list(set(aggregated_value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f7ea60e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sets the behavior of how each column would be aggregated by using dictionaries, where key = column name, and\n",
    "# value = the function (e.g. mva) or the name of the function (e.g. 'min')\n",
    "\n",
    "# columns that have multiple values that need to be combined into a flattened list\n",
    "mva_columns = ['age_ratings', 'category', 'external_games', 'game_modes', 'genres', 'release_dates', 'similar_games',\n",
    "              'summary', 'themes', 'language_supports', 'involved_companies', 'keywords', 'multiplayer_modes', 'status',\n",
    "              'alternative_names', 'bundles', 'franchises', 'game_engines', 'player_perspectives', 'game_localizations',\n",
    "              'collections', 'parent_game', 'collection', 'storyline', 'franchise']\n",
    "mva_dict = {key: mva for key in mva_columns}\n",
    "\n",
    "# columns that can be aggregated by taking the minimum value\n",
    "min_columns = ['id', 'first_release_date']\n",
    "min_dict = {key: 'min' for key in min_columns}\n",
    "\n",
    "# creates a single dictionary with the above aggregation behavioral dictionaries.\n",
    "# This dictionary will be passed onto the agg method of the groupby object\n",
    "column_aggregation_dict = {**mva_dict, **min_dict}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "00fc4eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# aggregates the df_games in order to remove duplicate entries resulting from multiple entries in the dataset itself, likely\n",
    "# by people opening multiple entries for the same game on igdb.\n",
    "\n",
    "df_games_agg = df_games.groupby(unique_game).agg(column_aggregation_dict).reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41a09b11",
   "metadata": {},
   "source": [
    "## merging sales and games data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "174783a4",
   "metadata": {},
   "source": [
    "Since a unique game is defined by the combination of its name, release year, and platform, it is necessary to make sure that all three of these can be matched. Release years and platforms are confined to a certain number of fixed values (e.g., 'pc' or 'ps4' for platforms and 2015 or 2019 for release years). These have already been dealt with above.\n",
    "\n",
    "Names of games, however, can wildly vary. Even the same game can have different spellings of its name (or could have been input differently, e.g., with colons and hyphens, or using digits vs. roman numerals). Instead of a one-to-one match like with release year and platform, names will be matched by closest match. This introduces a couple of complexities. First, the same name can be used by several games, often referring to older/newer releases of a title. So simply finding the closest match would not work, since this would result in finding the (first) closest match in the data set. This also reveals the second caveat here, which is that multiple names in one data set might match most closely to a single name in the other data set.\n",
    "\n",
    "These issues can be solved by making the assumption that in a given year and for a given platform, every game will have a different name. Put another way, every game for each year-platform combination will have a distinctively unique name. This allows to look for closest name matches within a given year-platform combination."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c5cf5af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function that returns a dictionary: key = release year, value = list of platforms for which games were made in that key year\n",
    "\n",
    "# Function that creates a dictionary of all combinations of year-platform in the data set. Keys are the release year and\n",
    "# values are lists of platforms for which games were made for that key-year (insofar as they appear in the data set).\n",
    "# Returns this year-platform dictionary.\n",
    "# Parameters:\n",
    "# - df: \n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "def generate_year_platform_dict(df, year_column='release_year', platform_column='platform'):\n",
    "    \n",
    "    return_dict = defaultdict(list)\n",
    "    \n",
    "    for year in df[year_column].unique():\n",
    "        for platform in df[df[year_column] == year][platform_column].unique():\n",
    "            return_dict[year].append(platform)\n",
    "    \n",
    "    return return_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9f5014c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all possible combination of year/platform found in the sales data\n",
    "\n",
    "sales_comb = generate_year_platform_dict(df_sales)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9d981426",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all possible combination of year/platform found in the games data\n",
    "\n",
    "games_comb = generate_year_platform_dict(df_games_agg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ff4b50b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates a dictionary that contains of release year(key) and list of platforms (list) that are shared between the two datasets\n",
    "\n",
    "shared_comb = {}\n",
    "\n",
    "for sales_year, sales_platform in sales_comb.items():\n",
    "    \n",
    "    # retrieves the list of platforms from df_game according to the year from df_sales; or None if there were no platforms\n",
    "    # for that sales year\n",
    "    games_platform = games_comb.get(sales_year, None)\n",
    "    \n",
    "    # add to that sales year the platforms that are shared for both datasets for that particular year\n",
    "    if games_platform:\n",
    "        shared_comb[sales_year] = list(set(sales_platform).intersection(games_platform))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "543e59e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rapidfuzz import process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f722fc26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the closest string from available choices\n",
    "# returns closest string found, its score (0 = completely diffent, 100 = identical string), and index of match in choices\n",
    "# if choices is a series, return the series index\n",
    "\n",
    "def find_closest_match(string, choices):\n",
    "    match, score, index = process.extractOne(string, choices)\n",
    "    return match, score, index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a6f6274a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# in order to not match the same string twice, once a match is found, this function removes that match from choices\n",
    "\n",
    "def find_match_and_remove(string, choices):\n",
    "    match, score, index = find_closest_match(string, choices)\n",
    "    choices = choices.drop(index)\n",
    "    return match, score, index, choices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c26debc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this code goes over all year/platform combinations, one at a time, in the sales data and tries to find a match in the game data.\n",
    "# it slowly builds up a new dataframe that contains those matches, keeping the index in df_games to merge it later on\n",
    "\n",
    "df_sales_name_matched = pd.DataFrame()\n",
    "\n",
    "for year, platforms in shared_comb.items():\n",
    "    for platform in platforms:\n",
    "#        print(f'Checking {year} + {platform}')\n",
    "        filtered_sales = df_sales[(df_sales['release_year'] == year) & (df_sales['platform'] == platform)][unique_game]\n",
    "        filtered_games = df_games_agg[(df_games_agg['release_year'] == year) & (df_games_agg['platform'] == platform)][unique_game]\n",
    "        \n",
    "        choices = filtered_games['name']\n",
    "        filtered_sales['closest_match'], filtered_sales['match_score'], filtered_sales['index_in_df_games_agg'], choices = zip(*filtered_sales['name'].apply(lambda x: find_match_and_remove(x, choices)))\n",
    "        \n",
    "        df_sales_name_matched = pd.concat([df_sales_name_matched, filtered_sales], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7b1e8f29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>platform</th>\n",
       "      <th>release_year</th>\n",
       "      <th>closest_match</th>\n",
       "      <th>match_score</th>\n",
       "      <th>index_in_df_games_agg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10 minute solution</td>\n",
       "      <td>wii</td>\n",
       "      <td>2010</td>\n",
       "      <td>10 minute solution</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>101in1 sports party megamix</td>\n",
       "      <td>wii</td>\n",
       "      <td>2010</td>\n",
       "      <td>101in1 sports party megamix</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2010 fifa world cup south africa</td>\n",
       "      <td>wii</td>\n",
       "      <td>2010</td>\n",
       "      <td>2010 fifa world cup south africa</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>active life explorer</td>\n",
       "      <td>wii</td>\n",
       "      <td>2010</td>\n",
       "      <td>active life explorer</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>2059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>alice in wonderland</td>\n",
       "      <td>wii</td>\n",
       "      <td>2010</td>\n",
       "      <td>alice in wonderland</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>3006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5262</th>\n",
       "      <td>zombiu</td>\n",
       "      <td>wiiu</td>\n",
       "      <td>2012</td>\n",
       "      <td>zombiu</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>82949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>507</th>\n",
       "      <td>brothers conflict precious baby</td>\n",
       "      <td>psv</td>\n",
       "      <td>2017</td>\n",
       "      <td>baboon</td>\n",
       "      <td>57.000000</td>\n",
       "      <td>6517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3323</th>\n",
       "      <td>phantasy star online 2 episode 4 deluxe package</td>\n",
       "      <td>psv</td>\n",
       "      <td>2017</td>\n",
       "      <td>cosmic star heroine</td>\n",
       "      <td>85.500000</td>\n",
       "      <td>14861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3322</th>\n",
       "      <td>phantasy star online 2 episode 4 deluxe package</td>\n",
       "      <td>ps4</td>\n",
       "      <td>2017</td>\n",
       "      <td>2dark deluxe edition</td>\n",
       "      <td>85.500000</td>\n",
       "      <td>470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1972</th>\n",
       "      <td>imagine makeup artist</td>\n",
       "      <td>ds</td>\n",
       "      <td>2020</td>\n",
       "      <td>marios star quest</td>\n",
       "      <td>42.105263</td>\n",
       "      <td>41914</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5273 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 name platform  release_year  \\\n",
       "0                                  10 minute solution      wii          2010   \n",
       "5                         101in1 sports party megamix      wii          2010   \n",
       "14                   2010 fifa world cup south africa      wii          2010   \n",
       "54                               active life explorer      wii          2010   \n",
       "113                               alice in wonderland      wii          2010   \n",
       "...                                               ...      ...           ...   \n",
       "5262                                           zombiu     wiiu          2012   \n",
       "507                   brothers conflict precious baby      psv          2017   \n",
       "3323  phantasy star online 2 episode 4 deluxe package      psv          2017   \n",
       "3322  phantasy star online 2 episode 4 deluxe package      ps4          2017   \n",
       "1972                            imagine makeup artist       ds          2020   \n",
       "\n",
       "                         closest_match  match_score  index_in_df_games_agg  \n",
       "0                   10 minute solution   100.000000                     56  \n",
       "5          101in1 sports party megamix   100.000000                    182  \n",
       "14    2010 fifa world cup south africa   100.000000                    397  \n",
       "54                active life explorer   100.000000                   2059  \n",
       "113                alice in wonderland   100.000000                   3006  \n",
       "...                                ...          ...                    ...  \n",
       "5262                            zombiu   100.000000                  82949  \n",
       "507                             baboon    57.000000                   6517  \n",
       "3323               cosmic star heroine    85.500000                  14861  \n",
       "3322              2dark deluxe edition    85.500000                    470  \n",
       "1972                 marios star quest    42.105263                  41914  \n",
       "\n",
       "[5273 rows x 6 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sales_name_matched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "bbb93390",
   "metadata": {},
   "outputs": [],
   "source": [
    "# match score of 90 seems to be the threshold where there are many good matches,\n",
    "# but anything below that results in many misses and only a few good matches.\n",
    "\n",
    "# then join in the columns from df_sales (after dropping the shared columns, i.e., unique_game) to the matched up rows\n",
    "df_sales_name_matched = df_sales_name_matched[df_sales_name_matched['match_score'] >= 90].join(df_sales.drop(unique_game, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "7f17d07d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merges the sales data (also containing the matched indices from the games data) with the aggregated games data\n",
    "\n",
    "final_columns_to_drop = ['index_in_df_games_agg']\n",
    "\n",
    "df_final = (pd.merge(df_sales_name_matched,\n",
    "                     df_games_agg.drop(unique_game, axis=1), left_on='index_in_df_games_agg', right_index=True)\n",
    "            .drop(final_columns_to_drop, axis=1)\n",
    "            .reset_index(drop=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "6bca0c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write the complete data set into a CSV file.\n",
    "\n",
    "df_final.to_csv('data_complete.csv', index_label='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "1b9fc7aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = pd.read_csv('data_complete.csv', index_col='Unnamed: 0')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
